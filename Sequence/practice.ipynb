{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import unicodedata\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda', index=0)\n",
    "else:\n",
    "    device = torch.device('cpu', index=0)\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>og</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42928-1500614319216-63344</td>\n",
       "      <td>You do not meet a man but frowns:</td>\n",
       "      <td>Every man you meet these days is frowning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>42928-1500614326583-89821</td>\n",
       "      <td>our bloods  No more obey the heavens than our...</td>\n",
       "      <td>Our bodies are in agreement with the planetar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A-63849</td>\n",
       "      <td>But what's the matter?</td>\n",
       "      <td>What's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42930-1500614347266-80123</td>\n",
       "      <td>His daughter, and the heir of's kingdom, whom...</td>\n",
       "      <td>The king wanted his daughter, the only heir to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42930-1500614355280-38326</td>\n",
       "      <td>she's wedded;  Her husband banish'd; she impr...</td>\n",
       "      <td>She's married, her husband is banished, she's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         id  \\\n",
       "0           0  42928-1500614319216-63344   \n",
       "1           1  42928-1500614326583-89821   \n",
       "2           2                    A-63849   \n",
       "3           3  42930-1500614347266-80123   \n",
       "4           4  42930-1500614355280-38326   \n",
       "\n",
       "                                                  og  \\\n",
       "0                 You do not meet a man but frowns:    \n",
       "1   our bloods  No more obey the heavens than our...   \n",
       "2                           But what's the matter?     \n",
       "3   His daughter, and the heir of's kingdom, whom...   \n",
       "4   she's wedded;  Her husband banish'd; she impr...   \n",
       "\n",
       "                                                   t  \n",
       "0         Every man you meet these days is frowning.  \n",
       "1   Our bodies are in agreement with the planetar...  \n",
       "2                                      What's wrong?  \n",
       "3  The king wanted his daughter, the only heir to...  \n",
       "4   She's married, her husband is banished, she's...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"./Datasets/final.csv\"\n",
    "dataset = pd.read_csv(data_dir)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' You do not meet a man but frowns: ',\n",
       " 'Every man you meet these days is frowning.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = list(zip(dataset['og'], dataset['t']))\n",
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_str(s):\n",
    "    final_str = \"\"\n",
    "    for ch in unicodedata.normalize('NFD', s):\n",
    "        if unicodedata.category(ch) != 'Mn':\n",
    "            final_str+=ch\n",
    "    \n",
    "    final_str = re.sub(r\"([.!:?'])\", r\" \\1\", final_str)\n",
    "    final_str = re.sub(r\"[^a-zA-Z:!?']+\", r\" \", final_str)\n",
    "    \n",
    "    return final_str.strip()\n",
    "\n",
    "def creatNormalizedPairs(pairs):\n",
    "    initpairs = []\n",
    "    for pair in pairs:\n",
    "        s1, s2 = pair\n",
    "        # print(len(s1))\n",
    "        s1 = normalize_str(s1.lower().strip())\n",
    "        s2 = normalize_str(s2.lower().strip())\n",
    "        initpairs.append([s1,s2])\n",
    "        \n",
    "    return initpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 25\n",
    "\n",
    "def filterPairs(initpairs):\n",
    "    pairs = []\n",
    "    for pair in initpairs:\n",
    "        if len(pair[0].split(\" \")) <= MAX_LENGTH and len(pair[1].split(\" \")) <= MAX_LENGTH:\n",
    "            pairs.append([pair])\n",
    "            \n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2idx = {'SOS':0, 'EOS':1}\n",
    "        self.idx2word = {0:'SOS', 1:'EOS'}\n",
    "        self.wordCnt = {}\n",
    "        self.nwords = 2\n",
    "        \n",
    "    def GenerateVocab(self, s):\n",
    "        for word in s.split(\" \"):\n",
    "            if word not in self.word2idx:\n",
    "                self.word2idx[word] = self.nwords\n",
    "                self.idx2word[self.nwords] = word\n",
    "                self.wordCnt[word] = 1\n",
    "                self.nwords+=1\n",
    "            else:\n",
    "                self.wordCnt[word]+=1    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inp_ids(sentence, langobj):\n",
    "    input_ids = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        input_ids.append(langobj.word2idx[word])\n",
    "        \n",
    "    if langobj.name == 'shake':\n",
    "        input_ids.append(langobj.word2idx['EOS'])\n",
    "    else:\n",
    "        input_ids.insert(0, langobj.word2idx['SOS'])\n",
    "        input_ids.append(langobj.word2idx['EOS'])\n",
    "        \n",
    "    return torch.tensor(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids2sentence(ids, vocab):\n",
    "    sentence = \"\"\n",
    "    print(id.ndim)\n",
    "    for id in ids.squeeze():\n",
    "        if id==0:\n",
    "            continue\n",
    "        word = vocab.idx2word[id.item()]\n",
    "        sentence += word + \" \"\n",
    "        if id == 1:\n",
    "            break;\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(customDataset, self).__init__()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        s, t = pairs[index]\n",
    "        s_input_ids = torch.zeros(MAX_LENGTH+1, dtype=torch.int64)\n",
    "        t_input_ids = torch.zeros(MAX_LENGTH+2, dtype=torch.int64)\n",
    "        s_input_ids[:len(s.splt(\" \"))+1] = get_inp_ids(s, shake)\n",
    "        t_input_ids[:len(t.split(\" \"))+2] = get_inp_ids(t, eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_layer, embed_layer, hidden_layer):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(input_layer, embed_layer)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.gru = nn.GRU(embed_layer, hidden_layer, batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.dropout(x)\n",
    "        _, hidden = self.gru(x)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_layer, hidden_layer, embed_layer):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(output_layer, embed_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.logsmax = nn.LogSoftmax(dim=-1)\n",
    "        self.gru = nn.GRU(embed_layer, hidden_layer, batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_layer, output_layer)\n",
    "        \n",
    "    def forward(self, x, hidden_wt):\n",
    "        x = self.embed(x)\n",
    "        x = self.relu(x)\n",
    "        out, hidden = self.gru(x, hidden_wt)\n",
    "        out = self.dense(out)\n",
    "        out = self.logsmax(out)\n",
    "        \n",
    "        return out, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    track_loss = 0\n",
    "    \n",
    "    for i, (s_ids, t_ids) in enumerate(dataloader):\n",
    "        s_ids = s_ids.to(device)\n",
    "        t_ids = t_ids.to(device)\n",
    "        \n",
    "        hidden_wt = encoder(s_ids)\n",
    "        \n",
    "        pred, _ = decoder(t_ids[:,0:-1], hidden_wt)\n",
    "        \n",
    "        gt = t_ids[:,1:]\n",
    "        pred = pred.view(-1,pred.shape[-1])\n",
    "        gt = gt.reshape(-1)\n",
    "        \n",
    "        loss = loss_fn(pred, gt)\n",
    "        track_loss+=loss.item()\n",
    "        \n",
    "        opte.zero_grad()\n",
    "        optd.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opte.step()\n",
    "        optd.step()\n",
    "    \n",
    "    return round(track_loss/len(dataloader), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one(e, n_epochs):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    track_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (s_ids, t_ids) in enumerate(test_dataloader):\n",
    "            s_ids = s_ids.to(device)\n",
    "            t_ids = t_ids.to(device)\n",
    "            \n",
    "            hidden_wt = encoder(s_ids)\n",
    "            # print(t_ids.ndim)\n",
    "            input_ids = t_ids[:,0]\n",
    "            # print(input_ids.ndim)\n",
    "            \n",
    "            pred = []\n",
    "            \n",
    "            if i+1==n_epochs:\n",
    "                pred_sentence=\"\"\n",
    "                \n",
    "            for j in range(1, MAX_LENGTH+2):\n",
    "                probs, _ = decoder(input_ids.unsqueeze(1),hidden_wt)\n",
    "                pred.append(probs)\n",
    "                _, input_ids = torch.topk(probs, dim=-1)\n",
    "                # print(input_ids.ndim) \n",
    "                input_ids=input_ids.squeeze(1,2)\n",
    "                # print(input_ids.ndim) \n",
    "                if e+1==n_epochs:\n",
    "                    word=eng.index2word[input_ids.item()]\n",
    "                    pred_sentence+=word + \" \"\n",
    "                if input_ids.item() == 1:\n",
    "                    break\n",
    "                \n",
    "            if e+1 == n_epochs:\n",
    "                src_sentence = ids2sentence(s_ids, shake)\n",
    "                gt_sentence = ids2sentence(t_ids, eng)\n",
    "                \n",
    "                print(\"\\n-----------------------------------\")\n",
    "                print(\"Source Sentence:\",src_sentence)\n",
    "                print(\"GT Sentence:\",gt_sentence)\n",
    "                print(\"Predicted Sentence:\",pred_sentence)\n",
    "                \n",
    "            pred_cat = torch.cat(pred, dim=1)\n",
    "            print(pred_cat.ndim)\n",
    "            pred_reshaped = pred_cat.view(-1, pred_cat.shape[-1])\n",
    "            gt=t_ids[:,1:j+1]\n",
    "            gt=gt.view(-1)\n",
    "            \n",
    "            loss=loss_fn(pred_reshaped, gt)\n",
    "            track_loss+=loss.item()\n",
    "            \n",
    "        if e+1==n_epochs:\n",
    "            print(\"-----------------------------------\")\n",
    "        return round(track_loss/len(test_dataloader), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "pairs = creatNormalizedPairs(pairs)\n",
    "pairs = filterPairs(pairs)\n",
    "length = len(pairs)\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
