{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 29 22:31:11 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.76                 Driver Version: 550.76         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2070 ...    Off |   00000000:0A:00.0  On |                  N/A |\n",
      "|  0%   49C    P5             24W /  215W |     519MiB /   8192MiB |     38%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A       682      G   /usr/lib/Xorg                                  22MiB |\n",
      "|    0   N/A  N/A       743      G   Hyprland                                      167MiB |\n",
      "|    0   N/A  N/A      6466      G   /usr/lib/firefox/firefox                      176MiB |\n",
      "|    0   N/A  N/A     10372      G   kitty                                          11MiB |\n",
      "|    0   N/A  N/A     16854      G   kitty                                           7MiB |\n",
      "|    0   N/A  N/A     29730      G   Xwayland                                       11MiB |\n",
      "|    0   N/A  N/A     32719      G   kitty                                          18MiB |\n",
      "|    0   N/A  N/A     72072      G   ...ictureAPI --variations-seed-version         42MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import opendatasets as od\n",
    "import string\n",
    "import random\n",
    "import unicodedata\n",
    "import os\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.transforms import Normalize, ToTensor\n",
    "\n",
    "from models.models import Encoder, Decoder, EncDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device(type=\"cuda\", index=0)\n",
    "else:\n",
    "    device=torch.device(type=\"cpu\", index=0)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>og</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42928-1500614319216-63344</td>\n",
       "      <td>You do not meet a man but frowns:</td>\n",
       "      <td>Every man you meet these days is frowning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>42928-1500614326583-89821</td>\n",
       "      <td>our bloods  No more obey the heavens than our...</td>\n",
       "      <td>Our bodies are in agreement with the planetar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A-63849</td>\n",
       "      <td>But what's the matter?</td>\n",
       "      <td>What's wrong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42930-1500614347266-80123</td>\n",
       "      <td>His daughter, and the heir of's kingdom, whom...</td>\n",
       "      <td>The king wanted his daughter, the only heir to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42930-1500614355280-38326</td>\n",
       "      <td>she's wedded;  Her husband banish'd; she impr...</td>\n",
       "      <td>She's married, her husband is banished, she's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         id  \\\n",
       "0           0  42928-1500614319216-63344   \n",
       "1           1  42928-1500614326583-89821   \n",
       "2           2                    A-63849   \n",
       "3           3  42930-1500614347266-80123   \n",
       "4           4  42930-1500614355280-38326   \n",
       "\n",
       "                                                  og  \\\n",
       "0                 You do not meet a man but frowns:    \n",
       "1   our bloods  No more obey the heavens than our...   \n",
       "2                           But what's the matter?     \n",
       "3   His daughter, and the heir of's kingdom, whom...   \n",
       "4   she's wedded;  Her husband banish'd; she impr...   \n",
       "\n",
       "                                                   t  \n",
       "0         Every man you meet these days is frowning.  \n",
       "1   Our bodies are in agreement with the planetar...  \n",
       "2                                      What's wrong?  \n",
       "3  The king wanted his daughter, the only heir to...  \n",
       "4   She's married, her husband is banished, she's...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"Datasets/final.csv\"\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51787\n",
      "('Every man you meet these days is frowning.', ' You do not meet a man but frowns: ')\n"
     ]
    }
   ],
   "source": [
    "pairs = list(zip(dataset['t'], dataset['og']))\n",
    "print(len(pairs))\n",
    "print(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    sres=''\n",
    "    for c in unicodedata.normalize('NFD', s):\n",
    "        if unicodedata.category(c) != 'Mn':\n",
    "            sres+=c\n",
    "    \n",
    "    sres = re.sub(r\"([.!?])\", r\" \\1\", sres) \n",
    "    sres = re.sub(r\"[^a-zA-Z!?]+\", r\" \", sres) \n",
    "    return sres.strip()\n",
    "\n",
    "def createNormalizedPairs(pairs):\n",
    "    initpairs = []\n",
    "    for pair in pairs:\n",
    "        s1, s2 = pair\n",
    "        s1=normalizeString(s1.lower().strip())\n",
    "        s2=normalizeString(s2.lower().strip())\n",
    "        # print(len(s1), \" \",len(s2))\n",
    "        initpairs.append([s1,s2])\n",
    "    # print(len(initpairs))\n",
    "    return initpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 15\n",
    "\n",
    "def filterpairs(initpairs):\n",
    "    eng_prefixes = (\n",
    "        \"i am \", \"i m \",\n",
    "        \"he is\", \"he s \",\n",
    "        \"she is\", \"she s \",\n",
    "        \"you are\", \"you re \",\n",
    "        \"we are\", \"we re \",\n",
    "        \"they are\", \"they re \",\n",
    "        \"i have \", \"i ve \",\n",
    "        \"you have \", \"you ve \",\n",
    "        \"we have \", \"we ve \",\n",
    "        \"they have \", \"they ve \",\n",
    "        \"is not \", \"isn t \",\n",
    "        \"are not \", \"aren t \",\n",
    "        \"was not \", \"wasn t \",\n",
    "        \"were not \", \"weren t \",\n",
    "        \"have not \", \"haven t \",\n",
    "        \"has not \", \"hasn t \",\n",
    "        \"had not \", \"hadn t \",\n",
    "        \"will not \", \"won t \",\n",
    "        \"would not \", \"wouldn t \",\n",
    "        \"do not \", \"don t \",\n",
    "        \"does not \", \"doesn t \",\n",
    "        \"did not \", \"didn t \",\n",
    "        \"can not \", \"can t \",\n",
    "        \"could not \", \"couldn t \",\n",
    "        \"should not \", \"shouldn t \",\n",
    "        \"might not \", \"mightn t \",\n",
    "        \"must not \", \"mustn t \"\n",
    "    )\n",
    "    pairs = []\n",
    "    for pair in initpairs:\n",
    "        if len(pair[0].split(\" \")) < MAX_LENGTH and len(pair[1].split(\" \")) < MAX_LENGTH and pair[0].lower().startswith(eng_prefixes):\n",
    "            pairs.append(pair)\n",
    "        \n",
    "    # print(\"Filtered pairs:\", len(pairs))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index={'SOS':0, 'EOS':1}\n",
    "        self.index2word={0:'SOS', 1:'EOS'}\n",
    "        self.word2count={}\n",
    "        self.nwords = 2\n",
    "        \n",
    "    def buildVocab(self, s):\n",
    "        for word in s.split(\" \"):\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.nwords\n",
    "                self.index2word[self.nwords] = word\n",
    "                self.word2count[word]=1\n",
    "                self.nwords+=1\n",
    "            else:\n",
    "                self.word2count[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_ids(sentence, langobj):\n",
    "    input_ids = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        input_ids.append(langobj.word2index[word])\n",
    "    \n",
    "       \n",
    "    if langobj.name=='shake':\n",
    "        input_ids.append(langobj.word2index['EOS'])\n",
    "    else:\n",
    "        input_ids.insert(0,langobj.word2index['SOS'])\n",
    "        input_ids.append(langobj.word2index['EOS'])\n",
    "    return torch.tensor(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        t, s = pairs[idx]\n",
    "        s_input_ids=torch.zeros(MAX_LENGTH+1, dtype=torch.int64)\n",
    "        t_input_ids=torch.zeros(MAX_LENGTH+2, dtype=torch.int64)\n",
    "        s_input_ids[:len(s.split(\" \"))+1]=get_input_ids(s, shake)\n",
    "        t_input_ids[:len(t.split(\" \"))+2]=get_input_ids(t, eng)\n",
    "        \n",
    "        return s_input_ids, t_input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    track_loss = 0\n",
    "    \n",
    "    for i, (s_ids, t_ids)in enumerate(train_dataloader):\n",
    "        s_ids = s_ids.to(device)\n",
    "        t_ids = t_ids.to(device)\n",
    "        encoder_hidden = encoder(s_ids)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        yhats, decoder_hidden = decoder(t_ids[:,0:-1], decoder_hidden)\n",
    "        \n",
    "        gt = t_ids[:,1:]\n",
    "        \n",
    "        yhats_reshaped = yhats.view(-1,yhats.shape[-1])\n",
    "        \n",
    "        gt=gt.reshape(-1)\n",
    "        \n",
    "        loss=loss_fn(yhats_reshaped,gt)\n",
    "        track_loss+=loss.item()\n",
    "        \n",
    "        opte.zero_grad()\n",
    "        optd.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opte.step()\n",
    "        optd.step()\n",
    "    \n",
    "    return track_loss/len(train_dataloader)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids2Sentence(ids,vocab):\n",
    "    sentence=\"\"\n",
    "    for id in ids.squeeze():\n",
    "        if id==0:\n",
    "            continue\n",
    "        word=vocab.index2word[id.item()]\n",
    "        sentence+=word + \" \"\n",
    "        if id==1:  \n",
    "            break\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_epoch(e,n_epochs):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    track_loss=0\n",
    "    with torch.no_grad():\n",
    "        for i, (s_ids,t_ids) in enumerate(test_dataloader):\n",
    "            s_ids=s_ids.to(device)\n",
    "            t_ids=t_ids.to(device)\n",
    "            \n",
    "            encoder_hidden = encoder(s_ids)\n",
    "            decoder_hidden = encoder_hidden\n",
    "            input_ids=t_ids[:,0]\n",
    "            yhats=[]\n",
    "            if e+1==n_epochs:\n",
    "                pred_sentence=\"\"\n",
    "            for j in range(1, MAX_LENGTH+2):\n",
    "                probs, decoder_hidden = decoder(input_ids.unsqueeze(1),decoder_hidden)\n",
    "                yhats.append(probs)\n",
    "                _,input_ids=torch.topk(probs,1,dim=-1)\n",
    "                input_ids=input_ids.squeeze(1,2)\n",
    "                if e+1==n_epochs:\n",
    "                    word=eng.index2word[input_ids.item()]\n",
    "                    pred_sentence+=word + \" \"\n",
    "                if input_ids.item() == 1:\n",
    "                    break;\n",
    "                \n",
    "            if e+1==n_epochs:\n",
    "                src_sentence=ids2Sentence(s_ids,shake)\n",
    "                gt_sentence=ids2Sentence(t_ids[:,1:],eng) \n",
    "                \n",
    "                print(\"\\n-----------------------------------\")\n",
    "                print(\"Source Sentence:\",src_sentence)\n",
    "                print(\"GT Sentence:\",gt_sentence)\n",
    "                print(\"Predicted Sentence:\",pred_sentence)\n",
    "                \n",
    "            yhats_cat=torch.cat(yhats,dim=1)\n",
    "            yhats_reshaped=yhats_cat.view(-1,yhats_cat.shape[-1])\n",
    "            gt=t_ids[:,1:j+1]\n",
    "            gt=gt.view(-1)\n",
    "            \n",
    "            loss=loss_fn(yhats_reshaped,gt)\n",
    "            track_loss+=loss.item()\n",
    "        \n",
    "        if e+1==n_epochs:    \n",
    "            print(\"-----------------------------------\")\n",
    "            \n",
    "        return track_loss/len(test_dataloader)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1423\n"
     ]
    }
   ],
   "source": [
    "pairs = createNormalizedPairs(pairs)\n",
    "pairs = filterpairs(pairs)\n",
    "length=len(pairs)\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you are like poison in my blood', 'thou rt poison to my blood']\n"
     ]
    }
   ],
   "source": [
    "print(pairs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Length: 2033\n",
      "Shakespere Vocab Length: 2228\n"
     ]
    }
   ],
   "source": [
    "shake = Vocab('shake')\n",
    "eng = Vocab('eng')\n",
    "\n",
    "for pair in pairs:\n",
    "    eng.buildVocab(pair[0])\n",
    "    shake.buildVocab(pair[1])\n",
    "    \n",
    "print(\"English Vocab Length:\",eng.nwords)\n",
    "print(\"Shakespere Vocab Length:\",shake.nwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = customDataset()\n",
    "train_dataset, test_dataset = random_split(dataset, [0.99,0.01])\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader=DataLoader(dataset=train_dataset,batch_size=batch_size, shuffle=False)\n",
    "test_dataloader=DataLoader(dataset=test_dataset,batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(2228, 300)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (rnn): GRU(300, 512, batch_first=True)\n",
      ") Decoder(\n",
      "  (embedding): Embedding(2033, 300)\n",
      "  (relu): ReLU()\n",
      "  (lsmax): LogSoftmax(dim=-1)\n",
      "  (rnn): GRU(300, 512, batch_first=True)\n",
      "  (linear): Linear(in_features=512, out_features=2033, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(shake.nwords).to(device)\n",
    "decoder = Decoder(eng.nwords).to(device)\n",
    "print(encoder,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.NLLLoss(ignore_index=0).to(device)\n",
    "lr=0.001\n",
    "opte=optim.Adam(params=encoder.parameters(), lr=lr, weight_decay=0.001)\n",
    "optd=optim.Adam(params=decoder.parameters(), lr=lr, weight_decay=0.001)\n",
    "\n",
    "n_epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=1, Train Loss=5.4379, Eval Loss=4.402\n",
      "Epoch=2, Train Loss=4.6169, Eval Loss=4.5406\n",
      "Epoch=3, Train Loss=4.2712, Eval Loss=4.6321\n",
      "Epoch=4, Train Loss=3.998, Eval Loss=4.9279\n",
      "Epoch=5, Train Loss=3.7426, Eval Loss=5.1585\n",
      "Epoch=6, Train Loss=3.5323, Eval Loss=5.4019\n",
      "Epoch=7, Train Loss=3.3376, Eval Loss=5.6446\n",
      "Epoch=8, Train Loss=3.1522, Eval Loss=5.6333\n",
      "Epoch=9, Train Loss=3.0099, Eval Loss=5.5565\n",
      "Epoch=10, Train Loss=2.8713, Eval Loss=5.565\n",
      "Epoch=11, Train Loss=2.7522, Eval Loss=5.653\n",
      "Epoch=12, Train Loss=2.6274, Eval Loss=5.5692\n",
      "Epoch=13, Train Loss=2.4892, Eval Loss=5.6997\n",
      "Epoch=14, Train Loss=2.3706, Eval Loss=5.8156\n",
      "Epoch=15, Train Loss=2.2436, Eval Loss=5.5963\n",
      "Epoch=16, Train Loss=2.1511, Eval Loss=5.3016\n",
      "Epoch=17, Train Loss=2.0633, Eval Loss=5.7814\n",
      "Epoch=18, Train Loss=1.9726, Eval Loss=5.7538\n",
      "Epoch=19, Train Loss=1.8928, Eval Loss=5.7836\n",
      "Epoch=20, Train Loss=1.8003, Eval Loss=5.5923\n",
      "Epoch=21, Train Loss=1.7025, Eval Loss=5.6358\n",
      "Epoch=22, Train Loss=1.6186, Eval Loss=5.7064\n",
      "Epoch=23, Train Loss=1.5627, Eval Loss=5.6456\n",
      "Epoch=24, Train Loss=1.5118, Eval Loss=5.2601\n",
      "Epoch=25, Train Loss=1.469, Eval Loss=5.9039\n",
      "Epoch=26, Train Loss=1.4136, Eval Loss=5.8788\n",
      "Epoch=27, Train Loss=1.358, Eval Loss=5.8747\n",
      "Epoch=28, Train Loss=1.3025, Eval Loss=5.3809\n",
      "Epoch=29, Train Loss=1.2702, Eval Loss=5.8851\n",
      "Epoch=30, Train Loss=1.2351, Eval Loss=5.8068\n",
      "Epoch=31, Train Loss=1.2068, Eval Loss=5.873\n",
      "Epoch=32, Train Loss=1.1735, Eval Loss=6.001\n",
      "Epoch=33, Train Loss=1.1313, Eval Loss=5.6482\n",
      "Epoch=34, Train Loss=1.1123, Eval Loss=5.8831\n",
      "Epoch=35, Train Loss=1.1014, Eval Loss=5.9936\n",
      "Epoch=36, Train Loss=1.0818, Eval Loss=6.3666\n",
      "Epoch=37, Train Loss=1.0701, Eval Loss=6.146\n",
      "Epoch=38, Train Loss=1.0685, Eval Loss=5.9202\n",
      "Epoch=39, Train Loss=1.0441, Eval Loss=5.9951\n",
      "Epoch=40, Train Loss=1.0195, Eval Loss=6.1179\n",
      "Epoch=41, Train Loss=0.9977, Eval Loss=5.9775\n",
      "Epoch=42, Train Loss=0.9821, Eval Loss=6.0595\n",
      "Epoch=43, Train Loss=0.9737, Eval Loss=6.0986\n",
      "Epoch=44, Train Loss=0.9614, Eval Loss=5.8984\n",
      "Epoch=45, Train Loss=0.9464, Eval Loss=5.9595\n",
      "Epoch=46, Train Loss=0.9538, Eval Loss=5.8946\n",
      "Epoch=47, Train Loss=0.9618, Eval Loss=6.0557\n",
      "Epoch=48, Train Loss=0.9657, Eval Loss=5.9585\n",
      "Epoch=49, Train Loss=0.9525, Eval Loss=6.2608\n",
      "Epoch=50, Train Loss=0.9359, Eval Loss=6.1963\n",
      "Epoch=51, Train Loss=0.929, Eval Loss=5.8061\n",
      "Epoch=52, Train Loss=0.9153, Eval Loss=5.8354\n",
      "Epoch=53, Train Loss=0.8932, Eval Loss=5.929\n",
      "Epoch=54, Train Loss=0.8965, Eval Loss=6.1345\n",
      "Epoch=55, Train Loss=0.8978, Eval Loss=6.1313\n",
      "Epoch=56, Train Loss=0.9022, Eval Loss=6.0432\n",
      "Epoch=57, Train Loss=0.8822, Eval Loss=6.0863\n",
      "Epoch=58, Train Loss=0.872, Eval Loss=5.5293\n",
      "Epoch=59, Train Loss=0.8664, Eval Loss=5.5476\n",
      "Epoch=60, Train Loss=0.8748, Eval Loss=5.9338\n",
      "Epoch=61, Train Loss=0.8612, Eval Loss=6.0734\n",
      "Epoch=62, Train Loss=0.8559, Eval Loss=6.3215\n",
      "Epoch=63, Train Loss=0.8418, Eval Loss=5.9971\n",
      "Epoch=64, Train Loss=0.8235, Eval Loss=6.244\n",
      "Epoch=65, Train Loss=0.8089, Eval Loss=5.9994\n",
      "Epoch=66, Train Loss=0.8001, Eval Loss=6.2891\n",
      "Epoch=67, Train Loss=0.7979, Eval Loss=6.2967\n",
      "Epoch=68, Train Loss=0.7935, Eval Loss=6.0283\n",
      "Epoch=69, Train Loss=0.805, Eval Loss=6.2571\n",
      "Epoch=70, Train Loss=0.7942, Eval Loss=5.9106\n",
      "Epoch=71, Train Loss=0.789, Eval Loss=5.902\n",
      "Epoch=72, Train Loss=0.7673, Eval Loss=6.0069\n",
      "Epoch=73, Train Loss=0.7521, Eval Loss=6.3272\n",
      "Epoch=74, Train Loss=0.7405, Eval Loss=6.2919\n",
      "Epoch=75, Train Loss=0.7395, Eval Loss=6.3746\n",
      "Epoch=76, Train Loss=0.733, Eval Loss=6.0833\n",
      "Epoch=77, Train Loss=0.7493, Eval Loss=6.1765\n",
      "Epoch=78, Train Loss=0.7593, Eval Loss=6.0197\n",
      "Epoch=79, Train Loss=0.7719, Eval Loss=5.9995\n",
      "Epoch=80, Train Loss=0.7495, \n",
      "-----------------------------------\n",
      "Source Sentence: wished my lord ! the gods grant o my lord ! EOS \n",
      "GT Sentence: you have my lord ? well may the gods grant oh my lord ! EOS \n",
      "Predicted Sentence: i m the king of all my good are lord sir EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: it is noised he hath a mass of treasure EOS \n",
      "GT Sentence: i have heard he has a huge treasure EOS \n",
      "Predicted Sentence: he s a very person dressed though EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: why i am glad on t this is well stand up EOS \n",
      "GT Sentence: i m glad ! this is good stand up EOS \n",
      "Predicted Sentence: i m glad to see the prisoner take of here EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: thou art a soldier only speak no more EOS \n",
      "GT Sentence: you re just a soldier don t speak anymore EOS \n",
      "Predicted Sentence: you re the one one who ever more EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: thou bleed st apace EOS \n",
      "GT Sentence: you re bleeding fast EOS \n",
      "Predicted Sentence: you have the same fortunes EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: it must be thought on EOS \n",
      "GT Sentence: we have to think about this EOS \n",
      "Predicted Sentence: he s afraid to come this to him angry EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: thine s too thick to shine EOS \n",
      "GT Sentence: you re too fat to shine EOS \n",
      "Predicted Sentence: you re too too blunt of about EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: madam they are for you EOS \n",
      "GT Sentence: they are for you madam EOS \n",
      "Predicted Sentence: they re coming too EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: is he so young a man and so old a lifter ? EOS \n",
      "GT Sentence: he is a young man used to carrying other people s things ? EOS \n",
      "Predicted Sentence: he s a stupid blockheaded flap eared son of a bitch and hesitant ? EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: he is coming sir he is coming i hear his straw rustle EOS \n",
      "GT Sentence: he s coming sir he s coming i can hear his straw rustling EOS \n",
      "Predicted Sentence: he s a bad but father t i waiting for him EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: i am maimed for ever help ho ! murder ! murder ! EOS \n",
      "GT Sentence: i am crippled forever help hey ! murder ! murder ! EOS \n",
      "Predicted Sentence: i m a subject fellow a fool ! of a ! EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: i have dined EOS \n",
      "GT Sentence: i ve already dined on beauty EOS \n",
      "Predicted Sentence: i have done EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: a thing for me ? it is a common thing EOS \n",
      "GT Sentence: you have a thing for me ? it is a common thing EOS \n",
      "Predicted Sentence: you re a villain man earth have EOS \n",
      "\n",
      "-----------------------------------\n",
      "Source Sentence: i am your accessary and so farewell EOS \n",
      "GT Sentence: i am your accomplice in this and so farewell EOS \n",
      "Predicted Sentence: i am forever your service your lordship EOS \n",
      "-----------------------------------\n",
      "Eval Loss=5.9346\n"
     ]
    }
   ],
   "source": [
    "for e in range(n_epochs):\n",
    "    print(\"Epoch=\",e+1, sep=\"\", end=\", \")\n",
    "    print(\"Train Loss=\", round(train_one_epoch(),4), sep=\"\", end=\", \")\n",
    "    print(\"Eval Loss=\",round(eval_one_epoch(e,n_epochs),4), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainenv",
   "language": "python",
   "name": "mainenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
